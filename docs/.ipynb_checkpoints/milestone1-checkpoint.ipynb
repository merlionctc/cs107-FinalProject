{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THIS CELL FOR FORMAT\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-c10da6ba-b1c7-476d-a044-0799bdfa7a18",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "# Milestone 1\n",
    "@merlionctc\n",
    "\n",
    "**Table of Contents**\n",
    "- [1. Introduction](#1-introduction)\n",
    "  - [1.1 Derivative](#11derivative)\n",
    "  - [1.2 Automatic Differentiation](#12automatuic-differentiation)\n",
    "- [2. Background](#Background)\n",
    "- [3. Usage](#Usage)\n",
    "  - [3.1 Installation](#31Installation)\n",
    "  - [3.2 How to use](#21How-to-use-)\n",
    "- [4. Software organization](#Software-Organization)\n",
    "- [5. Implementation](#Implementation)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1.Introduction\n",
    "\n",
    "We developed this package, `package_name`,  in the light of automatic differentiation. The package can help to automatically differentiate a function input into the program. The package includes modules of forward-mode differentiation and backward-mode differentiation.\n",
    "\n",
    "### 1.1 Derivatives\n",
    "\n",
    "Formally, for single variable case, the derivative of a function, if it exists, is defined as\n",
    "\n",
    "$$ f'(x) = \\lim_{h\\to0} \\frac{f(a+h) - f(a)}{h} $$\n",
    "\n",
    "to visualize, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value.\n",
    "\n",
    "Of course, derivatives may be generalized to functions of several real variables, and derivatives are useful in finding the maxima and minima of functions. Derivatives has a variety of applications in statistics and machine learning, and the process of finding a derivative is called *differentiation*.\n",
    "\n",
    "There are three ways of differentiation realized in computer science:\n",
    "- Numerical differentiation\n",
    "- Symbolic differentiation\n",
    "- Automatic differentiaton\n",
    "\n",
    "\n",
    "### 1.2 Auto Differentiation\n",
    "Automatic differentiation (AD), also called as algorithmic differentiation, is a set of techniques for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs <sup>1</sup>. It is not numerical differentiation, since numerical differentiation is the finite difference approximation of derivatives using the values of the original function evaluated at some sample points<sup>2</sup>. It is different from symbolic differentiation, since symbolic differentiation is the automatic manipulation of expressions for obtaining derivative expression<sup>3</sup>.\n",
    "\n",
    "The essence of AD is that all numerical computations are ultimately compositions of a finite set of elementary operations for which the derivatives are easily known<sup>4</sup>. The algorithm of AD breaks down a function by looking at the sequence of elementary arithmetic operations (addition, subtraction, multiplication and division) and elementary functions (exponential, logrithmatic, and trigonometry). By applying the chain rule repeatedly to these operations, derivatives of arbitrary order can be computed automatically, accurately to machine accuracy.\n",
    "\n",
    "This differentiation technique well-established and used with applications in different areas such as fluid dynamics, astronomy, and engineering design optimization.\n",
    "\n",
    "To sum up, there are two major advantages of using AD:\n",
    "- Computes derivatives to machine precision.\n",
    "- Does not rely on extensive mathematical derivations or expression trees, so it is easily applicable to a wide class of functions.\n",
    "\n",
    "## 2. Background\n",
    "\n",
    "Automatic differentiation relies on several vital mathematical foundations, some of which will be illustrated at this part. Based on these conceptions, it will be more resonable for users to understand the software.\n",
    "\n",
    "### 2.1 Chain Rule\n",
    "\n",
    "Chain Rule is the most important concept in AD. It enables us to deal with complex functions with several layers and arguments. With implementing chain rule, we can easily divide the original complicated functions into basic parts made up with elementary functions, of which we will know the concrete derivative expressions.\n",
    "\n",
    "Suppose there is a function $h\\left(u\\left(t\\right)\\right)$ and in order to calculate derivative of $h$ with respect to $t$, we should use chain rule. The derivative is $$\\dfrac{\\partial h}{\\partial t} = \\dfrac{\\partial h}{\\partial u}\\dfrac{\\partial u}{\\partial t}.$$\n",
    "\n",
    "In general, if a function $h$ has several arguments, or even its argument is a vector, so that $h = h(x(t))$ where  $x \\in R^n$ and $t \\in R^m $. In this way, $h$ is now the combination of $n$ functions, each of which has $m$ variables. The derivative of $h$ is now\n",
    "\n",
    " $$\\nabla_{t}h = \\sum_{i=1}^{n}{\\frac{\\partial h}{\\partial x_{i}}\\nabla y_{i}\\left(t\\right)}.$$\n",
    "\n",
    "### 2.2 Elementary functions\n",
    "\n",
    "Any complex function is made up with several elementary functions. As discussed above, we use chain rule to break it down and then focus on elementary functions to calulate their derivatives. \n",
    "\n",
    "In mathematics, an elementary function is a function of a single variable composed of particular simple functions. Elementary functions are typically defined as a sum, product and/or composition of many polynomials, rational functions, trigonometric and exponential functions, and their inverse functions.<sup>5</sup>\n",
    "\n",
    "On the other hand, we know the concrete mathematical expression of the elementary functions, which will be used directly in the later graph structure of calculations. \n",
    "\n",
    "### 2.3 Graph structure of calculations\n",
    "\n",
    "Take the example of $g = (x+y)*z$, we will first demonstrate the evaluation trace and then its corresponding computational graph.\n",
    "\n",
    "#### 2.3.1 Evaluation trace\n",
    "\n",
    "Let's evaluate g at the point (1,1,1). In the evaluation trace table, we will record the trace of each step, its  elementary operation as well as the corresponding numeric value at the point.\n",
    "\n",
    "| Trace | Elementary Operation | Numeric Value |\n",
    "| ----- | -------------------- | ------------- |\n",
    "| $x$   | 1                    | 1             |\n",
    "| $y$   | 1                    | 1             |\n",
    "| $z$   | 1                    | 1             |\n",
    "| $p$   | $x+y$                | 2             |\n",
    "| $f$   | $v_1*z$              | 2             |\n",
    "\n",
    "#### 2.3.2 Computational graph\n",
    "\n",
    "The above evaluation trace can be easily visualized with the computational graph below. The node will represent the trace and the edge will represent the elementary operation.\n",
    "\n",
    "<img src=\"computational_graph.png\">\n",
    "\n",
    "### 2.4 Forward mode and Reverse mode\n",
    "\n",
    "#### 2.4.1 Forward mode\n",
    "\n",
    "The evaluation trace above is just the path we will follow in forward mode. On top of that, we will also carry the derivatives. And we will take the derivative of g on x.\n",
    "\n",
    "| Trace | Elementary Operation | Numeric Value | Deri. on x    | Deri. Value on x |\n",
    "| ----- | -------------------- | ------------- | ------------- | ---------------- |\n",
    "| $x$   | 1                    | 1             | 1             | 1                |\n",
    "| $y$   | 1                    | 1             | 0             | 0                |\n",
    "| $z$   | 1                    | 1             | 0             | 0                |\n",
    "| $v_1$ | $x+y$                | 2             | $\\dot{x}$     | 1                |\n",
    "| $f$   | $v_1*z$              | 2             | $\\dot{v_1}*z$ | 1                |\n",
    "\n",
    "#### 2.4.1 Reverse mode\n",
    "\n",
    "It should be noticed that in forward mode, chain rule is not utilized. We just follow the evaluation trace and combine the derivatives of elementary functions together. But for reverse mode, we will implement chain rule. \n",
    "\n",
    "However, it is important to realize that the reverse mode also requires the evaluation trace on forward mode to have the derivatives on the elementary functions. Then we will use chain rule to reversely calculate the final derivative.\n",
    "\n",
    "- STEP1: Start with $v_1$\n",
    "\n",
    "   $$\\overline{v_1} = \\dfrac{\\partial f}{\\partial v_1} = 1.$$\n",
    "\n",
    "- STEP2: Use chain rule to calculate$\\overline{x}$\n",
    "\n",
    "   $$\\overline{x} = \\dfrac{\\partial f}{\\partial v_1}\\dfrac{\\partial v_1}{\\partial x}  = 1.$$\n",
    "\n",
    "- STEP3: Get the derivative on x\n",
    "\n",
    "   $$\\overline{x} = \\dfrac{\\partial f}{\\partial x}  = 1.$$\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "## Usage\n",
    "\n",
    "\n",
    " ### 3.1 Installation\n",
    " \n",
    "The package will be distributed through PyPI.\n",
    "\n",
    "To install AutoDiff using pip:\n",
    "\n",
    " ```bash\n",
    " pip install AutoDiff\n",
    " ```\n",
    "\n",
    "This will also install NumPy and Parser as dependency.\n",
    "\n",
    "\n",
    " \n",
    " ### 3.2 How to Use\n",
    "\n",
    "Here is an example that serves that a quick start tutorial.\n",
    "\n",
    "\n",
    "```python\n",
    "# The standard way to import AutoDiff:\n",
    "import AutoDiff as ad\n",
    "\n",
    "# Create a function:\n",
    "f = '(x+y)*z'\n",
    "var = {\"x\": 1, \"y\": 2, \"z\": 3}\n",
    "\n",
    "# instantiate AD objects\n",
    "fwd = ad.Forward(f, var)\n",
    "rvs = ad.Reverse(f, var)\n",
    "fwd.get_value()\n",
    "rvs.get_value()\n",
    "\n",
    "# Jacobian\n",
    "f_jcb = ['x+x*exp(y)','sin(x)+y*cos(x)']\n",
    "var_jcb = {\"x\": 4, \"y\": 3}\n",
    "fwd_jcb = ad.Forward(f_jcb, var_jcb)\n",
    "rvs_jcb = ad.Reverse(f_jcb, var_jcb)\n",
    "fwd_jcb.get_jacobian()\n",
    "rvs_jcb.get_jacobian()\n",
    "```\n",
    "\n",
    "\n",
    "There are x public functions of this API:\n",
    "\n",
    "`Forward(AutoDiff)`: Class that does forward mode differentiation of the function\n",
    "\n",
    "`Reverse(AutoDiff)`: Class that does reverse mode differentiation of the function\n",
    "\n",
    "`get_value()`: Getting value of differentation results\n",
    "\n",
    "`get_jacobian()`: Getting Jacobian matrix of differentiation results. To get Jacobian, the input must be a 2-D numpy array, which gives an output of 2-D numpy array.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Software Organization\n",
    "\n",
    "Discuss how you plan on organizing your software package.\n",
    "\n",
    "* Directory Structure\n",
    "\n",
    "```\n",
    "project\n",
    "│   README.md\n",
    "│   .travis.yml  \n",
    "│   LICENSE\n",
    "│\n",
    "└───AutoDiff\n",
    "│   │   README.md\n",
    "│   │   Func Parser (module)\n",
    "│   │   Forward mode (class)\n",
    "│   │   Reverse mode (class)\n",
    "│   │   Interface\n",
    "│   └───subfolder1\n",
    "│       │   file111.txt\n",
    "│       │   file112.txt\n",
    "│       │   ...\n",
    "│\n",
    "└───Test suite\n",
    "│   │   README.md\n",
    "│   │   Func Parser Test\n",
    "│   │   Forward mode Test\n",
    "│   │   Reverse mode Test\n",
    "│   │   Interface Test\n",
    "│   │   ...\n",
    "└───Docs\n",
    "│   │   README.md\n",
    "│   │   milestone1.md\n",
    "\n",
    "```\n",
    "\n",
    "* Modules to include\n",
    "\n",
    " math: mathematical, algebric operations\n",
    "\n",
    " numpy: supports computations for large, multi-dimensional arrays and matrices. \n",
    "\n",
    " [parser](https://docs.python.org/3.0/library/parser.html): we will build on this standard library `parser` to parse \n",
    " the function string into expression tree. Currently, this parser only handles parsing and evaluating basic arithmetic operations with numbers. \n",
    " We will also use Numpy and Math for evaluating formulas.\n",
    "\n",
    "\n",
    "* Test suite design\n",
    "\n",
    " The test suite will be included in the Test suite sub-directory. And both TravisCI and Coveralls will be used to check the codes coverage and test integration.\n",
    "\n",
    "\n",
    "* Package distribution\n",
    "\n",
    " PyPI will be used to distribute the package.\n",
    "  \n",
    "\n",
    "* How will you package your software? Will you use a framework? If so, which one and why? If not, why not?\n",
    "\n",
    "  We will package our software using [Python Package Index (PyPi)](https://pypi.org/),\n",
    "  and following Package Python Projects [Tutorial](https://packaging.python.org/tutorials/packaging-projects/)\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "Discuss how you plan on implementing the forward mode of automatic differentiation.\n",
    "\n",
    "* Core data structures\n",
    "\n",
    "  The user can input a string as the function expression. We will then use the above cited parser package to parse the formula. \n",
    "  Then a formula data structure will then be created, encoding the user's input as an abstract syntax tree. In this way, we will implement the  evaluation and differentiation.\n",
    "\n",
    "\n",
    "* Implemented classes\n",
    "\n",
    "  * Forward mode: This class will implement differention and calculate derivatives through forward mode.\n",
    "\n",
    "  * Reverse mode: This class will implement chain rule to calculate derivatives through reverse mode.\n",
    "\n",
    "  * Elementary function: This class will overwrite and redefine the parsed string as elementary functions.\n",
    "\n",
    " \n",
    "* Method and attributes of the classes\n",
    "\n",
    "  * Forward mode: \n",
    "\n",
    "```python\n",
    "def __init__(self, f, var):\n",
    "     self.f = f\n",
    "     self.var = var\n",
    "     \n",
    "def get_value(self, **kwargs):\n",
    "    # **kwargs: var = 'all','x','y' etc.\n",
    "    # all will be \n",
    "    # calculate the derivative of f on var through forward mode to specific value\n",
    "    return self.diff\n",
    "     \n",
    "def get_jacobian(self, **kwargs):\n",
    "    # **kwargs: var = 'all','x','y' etc.\n",
    "    # calculate the derivative of f on var through forward mode with jacobian\n",
    "    return self.diff\n",
    "     \n",
    "def get_expression(self, **kwargs):\n",
    "    # **kwargs: var = 'all','x','y' etc.\n",
    "    # return the list of derivative expression of the parsed formula.\n",
    "    return self.express\n",
    "```\n",
    "\n",
    "  * Reverse mode:\n",
    "\n",
    "```python\n",
    "def __init__(self, f, var):\n",
    "    self.f = f\n",
    "    self.var = var\n",
    "     \n",
    "def get_value(self, **kwargs):\n",
    "   # **kwargs: var = 'all','x','y' etc.\n",
    "   # all\n",
    "   # calculate the derivative of f on var through reverse mode to specific value\n",
    "    return self.diff\n",
    "     \n",
    "def get_jacobian(self, **kwargs):\n",
    "   # **kwargs: var = 'all','x','y' etc.\n",
    "   # calculate the derivative of f on var through reverse mode with jacobian\n",
    "    return self.diff\n",
    "     \n",
    "def get_expression(self, **kwargs):\n",
    "   # **kwargs: var = 'all','x','y' etc.\n",
    "   # return the list of derivative expression of the parsed formula.\n",
    "    return self.express\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  * Elementary function :\n",
    "  \n",
    "  Since we parse the string expression into a tree, we expect to let the computer recognize elementary\n",
    "  function and evaluate into expressions or numerical values. The methods are the followings:\n",
    " \n",
    "```python\n",
    " __init__\n",
    " sin()\n",
    " cos()\n",
    " exp()\n",
    " pow()\n",
    " log()\n",
    " ...\n",
    "\n",
    " \n",
    " def __init__(self):\n",
    "\n",
    " def sin(self):\n",
    "     return ##the expression of a expression\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "* External dependencies\n",
    "\n",
    "  As we mentioned in the Software Organization - Modules to include, we will use standard library `parser` and \n",
    "  extend it to parse the function entered as string. Also, the project will highly rely on `numpy` and `math`.\n",
    "  \n",
    "\n",
    "* How will you deal with elementary functions like sin, sqrt, log, and exp (and all the others)?\n",
    "\n",
    "  We will parse the string and use Regex to match a pre-defined elementary functions. \n",
    "  A pre-defined class will implement all relevant operators and elementary functions using Python `math` library.\n",
    "  Some special number such as `pi` and `e` will also be included in the class as pre defined constant.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### reference\n",
    "[[1]](https://www.jmlr.org/papers/volume18/17-468/17-468.pdf): Baydin, Atilim Gunes; Pearlmutter, Barak; Radul, Alexey Andreyevich; Siskind, Jeffrey (2018). \"Automatic differentiation in machine learning: a survey\". Journal of Machine Learning Research. 18: 1–43.\n",
    "\n",
    "[[2]](https://fac.ksu.edu.sa/sites/default/files/numerical_analysis_9th.pdf):Rirchard L. Burden and J. Douglas Faires. Numerical Analysis. Brooks/Cole, 2001.\n",
    "\n",
    "[[3]](https://www.springer.com/gp/book/9783540654667):Johannes Grabmeier and Erich Kaltofen. Computer Algebra Handbook: Foundations, Applications, Systems. Springer, 2003\n",
    "\n",
    "[[4]](https://www.jstor.org/stable/24103956): Arun Verma. An introduction to automatic differentiation. Current Science, 78(7):804–7,\n",
    "2000.\n",
    "\n",
    "[[5]](https://www.worldcat.org/oclc/31441929):  Spivak, Michael. (1994). *Calculus* (3rd ed.). Houston, Tex.: Publish or Perish. p. 359."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-b0f5ee3d-1b05-4a26-a88b-50006f34d9a7",
    "output_cleared": false,
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-469495a4-778d-4ae8-9db0-372264080984",
    "output_cleared": false,
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6e15877c-964e-4b84-bf2c-3775b98c0a30",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
