{"cells":[{"cell_type":"code","metadata":{"deepnote_cell_type":"code","output_cleared":false,"source_hash":"9e5190f0","execution_start":1604200362789,"execution_millis":91,"cell_id":"00000-3895cf84-c8df-4c3f-9203-62819e26efc7"},"source":"# RUN THIS CELL FOR FORMAT\nimport requests\nfrom IPython.core.display import HTML\nstyles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\nHTML(styles)","execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\nblockquote { background: #AEDE94; }\nh1 { \n    padding-top: 25px;\n    padding-bottom: 25px;\n    text-align: left; \n    padding-left: 10px;\n    background-color: #DDDDDD; \n    color: black;\n}\nh2 { \n    padding-top: 10px;\n    padding-bottom: 10px;\n    text-align: left; \n    padding-left: 5px;\n    background-color: #EEEEEE; \n    color: black;\n}\n\ndiv.exercise {\n\tbackground-color: #ffcccc;\n\tborder-color: #E9967A; \t\n\tborder-left: 5px solid #800080; \n\tpadding: 0.5em;\n}\n\ndiv.exercise-r {\n\tbackground-color: #fce8e8;\n\tborder-color: #E9967A; \t\n\tborder-left: 5px solid #800080; \n\tpadding: 0.5em;\n}\n\n\nspan.sub-q {\n\tfont-weight: bold;\n}\ndiv.theme {\n\tbackground-color: #DDDDDD;\n\tborder-color: #E9967A; \t\n\tborder-left: 5px solid #800080; \n\tpadding: 0.5em;\n\tfont-size: 18pt;\n}\ndiv.gc { \n\tbackground-color: #AEDE94;\n\tborder-color: #E9967A; \t \n\tborder-left: 5px solid #800080; \n\tpadding: 0.5em;\n\tfont-size: 12pt;\n}\np.q1 { \n    padding-top: 5px;\n    padding-bottom: 5px;\n    text-align: left; \n    padding-left: 5px;\n    background-color: #EEEEEE; \n    color: black;\n}\nheader {\n   padding-top: 35px;\n    padding-bottom: 35px;\n    text-align: left; \n    padding-left: 10px;\n    background-color: #DDDDDD; \n    color: black;\n}\n</style>\n\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Milestone 1\n@merlionctc\n\n**Table of Contents**\n- [1. Introduction](#1.-Introduction)\n  - [1.1 Derivative](#1.1-Derivatives)\n  - [1.2 Automatic Differentiation](#1.2-Auto-Differentiation)\n- [2. Background](#2.-Background)\n  - [2.1 Chain Rule](#2.1-Chain-Rule) \n  - [2.2 Elementary functions](#2.2-Elementary-functions) \n  - [2.3 Forward mode](#2.3-Forward-mode) \n  - [2.4 Reversed mode](#2.4-Reversed-mode) \n  - [2.5 Dual Number](#2.5-Dual-Number) \n- [3. Usage](#3.-Usage)\n  - [3.1 Installation](#3.1-Installation)\n  - [3.2 How to use](#3.2-How-to-Use)\n- [4. Software organization](#4.-Software-Organization)\n- [5. Implementation](#5.-Implementation)\n- [6. Reference](#6.-Reference)\n- [7. Feedback](#7.-Feedback)\n\n\n\n\n## 1. Introduction\n\nWe developed this package, `AutoDiff`,  in the light of automatic differentiation. The package can help to automatically differentiate a function input into the program. The package includes modules of forward-mode differentiation and backward-mode differentiation.\n\n### 1.1 Derivatives\n\nFormally, for single variable case, the derivative of a function, if it exists, is defined as\n\n$$ f'(x) = \\lim_{h\\to0} \\frac{f(a+h) - f(a)}{h} $$\n\nto visualize, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value.\n\nOf course, derivatives may be generalized to functions of several real variables, and derivatives are useful in finding the maxima and minima of functions. Derivatives has a variety of applications in statistics and machine learning, and the process of finding a derivative is called *differentiation*.\n\nThere are three ways of differentiation realized in computer science:\n- Numerical differentiation\n- Symbolic differentiation\n- Automatic differentiaton\n\n\n### 1.2 Auto Differentiation\nAutomatic differentiation (AD), also called as algorithmic differentiation, is a set of techniques for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs <sup>1</sup>. It is not numerical differentiation, since numerical differentiation is the finite difference approximation of derivatives using the values of the original function evaluated at some sample points<sup>2</sup>. It is different from symbolic differentiation, since symbolic differentiation is the automatic manipulation of expressions for obtaining derivative expression<sup>3</sup>.\n\nThe essence of AD is that all numerical computations are ultimately compositions of a finite set of elementary operations for which the derivatives are easily known<sup>4</sup>. The algorithm of AD breaks down a function by looking at the sequence of elementary arithmetic operations (addition, subtraction, multiplication and division) and elementary functions (exponential, logrithmatic, and trigonometry). By applying the chain rule repeatedly to these operations, derivatives of arbitrary order can be computed automatically, accurately to machine accuracy.\n\nThis differentiation technique well-established and used with applications in different areas such as fluid dynamics, astronomy, and engineering design optimization.\n\nTo sum up, there are two major advantages of using AD:\n- Computes derivatives to machine precision.\n- Does not rely on extensive mathematical derivations or expression trees, so it is easily applicable to a wide class of functions.\n\n## 2. Background\n\nAutomatic differentiation relies on several vital mathematical foundations, some of which will be illustrated at this part. Based on these conceptions, it will be more resonable for users to understand the software.\n\n### 2.1 Chain Rule\n\nChain Rule is the most important concept in AD. It enables us to deal with complex functions with several layers and arguments. With implementing chain rule, we can easily divide the original complicated functions into basic parts made up with elementary functions, of which we will know the concrete derivative expressions.\n\nSuppose there is a function $h\\left(u\\left(t\\right)\\right)$ and in order to calculate derivative of $h$ with respect to $t$, we should use chain rule. The derivative is $$\\dfrac{\\partial h}{\\partial t} = \\dfrac{\\partial h}{\\partial u}\\dfrac{\\partial u}{\\partial t}.$$\n\nIn general, if a function $h$ has several arguments, or even its argument is a vector, so that $h = h(x(t))$ where  $x \\in R^n$ and $t \\in R^m $. In this way, $h$ is now the combination of $n$ functions, each of which has $m$ variables. The derivative of $h$ is now\n\n $$\\nabla_{t}h = \\sum_{i=1}^{n}{\\frac{\\partial h}{\\partial x_{i}}\\nabla y_{i}\\left(t\\right)}.$$\n\n### 2.2 Elementary functions\n\nAny complex function is made up with several elementary functions. As discussed above, we use chain rule to break it down and then focus on elementary functions to calulate their derivatives. \n\nIn mathematics, an elementary function is a function of a single variable composed of particular simple functions. Elementary functions are typically defined as a sum, product and/or composition of many polynomials, rational functions, trigonometric and exponential functions, and their inverse functions.<sup>5</sup>\n\nOn the other hand, we know the concrete mathematical expression of the elementary functions, which will be used directly in the later graph structure of calculations. \n\n\n### 2.3 Forward mode\n\n#### 2.3.1 Evaluation trace\n\nTake the example of $g = (x+y)*z$, we will first demonstrate the evaluation trace and then its corresponding computational graph.\n\nLet's evaluate g at the point (1,1,1). In the evaluation trace table, we will record the trace of each step, its  elementary operation as well as the corresponding numeric value at the point.\n\n| Trace | Elementary Operation | Numeric Value |\n| ----- | -------------------- | ------------- |\n| $x$   | 1                    | 1             |\n| $y$   | 1                    | 1             |\n| $z$   | 1                    | 1             |\n| $p$   | $x+y$                | 2             |\n| $f$   | $v_1*z$              | 2             |\n\n#### 2.3.2 Computational graph\n\nThe above evaluation trace can be easily visualized with the computational graph below. The node will represent the trace and the edge will represent the elementary operation.\n\n<img src=\"forward_mode.png\">\n\n*Note: If you cannot see the image, please right click and open image in new tab*\n\n#### 2.3.3 Explanation\nThe evaluation trace above is just the path we will follow in forward mode. On top of that, we will also carry the derivatives. And we will take the derivative of g on x.\n\n| Trace | Elementary Operation | Numeric Value | Deri. on x    | Deri. Value on x |\n| ----- | -------------------- | ------------- | ------------- | ---------------- |\n| $x$   | 1                    | 1             | 1             | 1                |\n| $y$   | 1                    | 1             | 0             | 0                |\n| $z$   | 1                    | 1             | 0             | 0                |\n| $v_1$ | $x+y$                | 2             | $\\dot{x}$     | 1                |\n| $f$   | $v_1*z$              | 2             | $\\dot{v_1}*z$ | 1                |\n\n### 2.4 Reverse mode\n\n#### 2.4.1 Explanation\n\nIt should be noticed that in forward mode, chain rule is not utilized. We just follow the evaluation trace and combine the derivatives of elementary functions together. But for reverse mode, we will implement chain rule. \n\nHowever, it is important to realize that the reverse mode also requires the evaluation trace on forward mode to have the derivatives on the elementary functions. Then we will use chain rule to reversely calculate the final derivative.\n\nThe steps we use to implement reverse mode based on the evaluation trace in forward mode is as follows.\n\n- STEP1: Start with $v_1$\n\n   $$\\overline{v_1} = \\dfrac{\\partial f}{\\partial v_1} = 1.$$\n\n- STEP2: Use chain rule to calculate$\\overline{x}$\n\n   $$\\overline{x} = \\dfrac{\\partial f}{\\partial v_1}\\dfrac{\\partial v_1}{\\partial x}  = 1.$$\n\n- STEP3: Get the derivative on x\n\n   $$\\overline{x} = \\dfrac{\\partial f}{\\partial x}  = 1.$$\n\n#### 2.4.2 Computational graph\n\nIn reverse mode, we just reversely implement chain rule to get the derivatives. And the computational graph for reverse mode is as follows.\n\n<img src=\"reverse_mode.png\">\n\n*Note: If you cannot see the image, please right click and open image in new tab*\n\n ### 2.5 Dual Number\n \n A dual number has a real part and a dual part. Say we have $z = a + b\\epsilon $. Then $a$ is the real part and $b$ is the dual part.\n\n For $\\epsilon$, we define $\\epsilon ^2 = 0$ but $\\epsilon$ is not zero.\n \n Dual Number is really useful when we want to calculate derivatives of a function. For example, say we have\n\n $$ x = a + b\\epsilon,   y = x^2$$\n \n Then we can derive\n \n $$y = (a + b\\epsilon)^2 = a^2 + 2ab\\epsilon + b^2\\epsilon^2 = a^2 + 2ab\\epsilon$$\n\n Therefore, it is really convenient to get the value of y from real part and get derivative of y from dual part. This is what we will implement in our codes.\n \n \n\n\n","metadata":{"deepnote_cell_type":"markdown","output_cleared":false,"tags":[],"cell_id":"00001-9cd35fec-afc5-4e11-9dce-8ab8243ca43f"}},{"cell_type":"markdown","source":"","metadata":{"deepnote_cell_type":"markdown","output_cleared":false,"tags":[],"cell_id":"00002-becde001-1c5b-45ff-aac0-b0108dc812ad"}},{"cell_type":"markdown","source":"","metadata":{"deepnote_cell_type":"markdown","output_cleared":false,"tags":[],"cell_id":"00003-4e8ec0d2-cf25-4079-852a-b6df43e71fae"}},{"cell_type":"markdown","source":"## 3. Usage\n\n\n ### 3.1 Installation\n \nThe package will be distributed through PyPI (Not yet implemented, a usage example is shown on demo.py).\n\nTo install AutoDiff using pip:\n\n ```bash\n pip install AutoDiff\n ```\n\nThis will also install all required documents as dependency.\n\nFor now, to get started, please do git clone on our project and test by using `demo.py`\n\n ```bash\n git clone https://github.com/merlionctc/cs107-FinalProject.git\n ```\n \nTo ensure you have your enviroment and all required package setup, \n\n ```bash\n pip install -r requirements.txt\n ```\n\nTo run a simple test case and demo we provided.\n\n ```bash\n python3 AutoDiff/src/autodiff/demo.py\n ```\n\n\n\n\n### 3.2 How to Use\n\nHere is an example that serves that a quick start tutorial.\n\n\n```python\n# The standard way to import AutoDiff:\nfrom model import *\nfrom dual_class import *\nfrom elementary import *\n\n# First Step: User instantiate variables\n# val: value of variable that you start with\n# der: value of the derivative of variable that you start with, usually starting with 1\n# loc: The location/index this variable when there are multiple input variables for the target function(s). For example, if you initialize x1 first, the loc will be 0; then you initialize y1, the loc will increment to 1\n# length: The length/number of the total variables that will be input when there are multiple input variables for the target function(s).For example, if you want to initialize x1,y1 and z1, the length will be 3, for each variable in the initialization process\n\nx1 = Dual(val = 1, der=1, loc = 0, length = 3)\ny1 = Dual(val = 2, der=1, loc = 1, length = 3)\nz1 = Dual(val = 5, der=1, loc = 2, length = 3)\n\n# Second Step: User inputs function, based on above variables\nf1 = 3 * x1 + 4 * y1 * 2 - z1\n\n# Third Step: User instantiate AutoDiff.Forward class \nfwd_test = Forward(f1)\n\n# Four Step: User could choose to call instance method get_value() to get value of func\nprint(fwd_test.get_value())\n\n# Five Step: User could choose to call instance method get_der() to get der of func\n# Note: This method will return a derivative vector w.r.t to all variables \nprint(fwd_test.get_der())\n\n# Sixth Step: User could choose to call instance method get_der(var) to get der of func\n# Note: This method will return a derivative vector w.r.t to specific variables you input\nprint(fwd_test.get_der(x1))\n```\n\n\nThere are 2 classes inherited from `AutoDiff` and 3 public functions of this API:\n\n`Forward(AutoDiff)`: Class that does forward mode differentiation of the function\n\n`Reverse(AutoDiff)`: Class that does reverse mode differentiation of the function. (This is a future implementation)\n\n`get_value()`: Getting value of differentation results\n\n`get_der(*args)`: Getting derivative of all differentation results in a vector, or w.r.t to sepcific variable.\n\n`get_jacobian()`: Getting Jacobian matrix of differentiation results. To get Jacobian, the input must be a 2-D numpy array, which gives an output of 2-D numpy array.\n\n`get_expression()`: Getting a symbolic derivative expression of the function. (This is a future implementation)\n\nNote: these are subject to change in the development process\n\n\n","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00004-e763b313-61d5-4be4-b018-ef82c11749e3"}},{"cell_type":"markdown","source":"","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00005-9c1a8a46-17fe-4ad6-9448-238e9c1e70b1"}},{"cell_type":"markdown","source":"## 4. Software Organization\n\nDiscuss how you plan on organizing your software package.\n\n* Directory Structure\n\n```\nAutoDiff\n│   README.md\n│   .travis.yml  \n│   LICENSE\n│\n└───src\n    │\n    └─── autodiff\n    │   │   Func Parser (module, not yet implemented)\n    │   │   interface.py (Interface, not yet implemented)\n    │   │   model (AutoDiff main class with Forward/Reverse mode)\n    │   │   elementary.py (Elementary Function class)\n    │   │   dual_class.py (Dual Number Class)\n    │   │   demo.py (A demo to usage of package)\n│        ...\n│\n└───tests\n│   │   autodiff_test.py\n│   │   dual_class_test.py\n│   │   elementary_test.py\n│   │   Func Parser Test (*TBC)\n│   │   Interface Test (*TBC)\n│   │   ...\n└───Docs\n│   │   README.md\n│   │   milestone1.ipynb\n│   │   milestone2_progress.ipynb\n│   │   milestone2.ipynb\n\n```\n\n* **Modules to Include**\n\n math: mathematical, algebric operations\n\n numpy: supports computations for large, multi-dimensional arrays and matrices. \n\n [parser](https://docs.python.org/3.0/library/parser.html): (This is a future implementation). We will build a user interface in the future that asking user to input directly the expression she/he wants to work with. We will build on this standard library `parser` to parse \n the function string into expression tree. Currently, this parser only handles parsing and evaluating basic arithmetic operations with numbers. \n \n We will also use Numpy and Math for evaluating formulas.\n\n\n* **Test Suite Design**\n\n We used Pytest as our test suite. We tested all of our implemented classes on every single instance methods.\n We also tested on special and corner cases such as simplication, real number etc. \n The whole test suite is included in the *test* sub-directory. \n And both TravisCI and Coveralls will be used to check the codes coverage and test integration.\n\n\n* **Package Distribution**\n\n  We will distribute our software using [Python Package Index (PyPi)](https://pypi.org/).\n  Currently, we used Python project structure from [PyScaffold](https://pypi.org/project/PyScaffold/).\n\n* **Software Package**\n\n  We will package using the standard packaging tool ([setuptools](https://packaging.python.org/key_projects/#setuptools)), and following Package Python Projects [Tutorial](https://packaging.python.org/tutorials/packaging-projects/).\n\n  \n\n\n\n\n","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00006-73c87071-0ebe-4d4f-b71d-68e13c9fe90e"}},{"cell_type":"markdown","source":"","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00007-d1a88caa-bd47-4f57-9947-31a62019b3d3"}},{"cell_type":"markdown","source":"## 5. Implementation\n\nDiscuss how you plan on implementing the forward mode of automatic differentiation.\n\n* **Core Data Structures**\n\n  * The user will start by initializing variables using Dual class.\n\n  * Numpy Array:\n  Our core data structure of Dual class and its operation is built upon numpy array.\n  The elementary function is also operated on numpy array and real numbers.\n  We store each variable its corresponding value, derivative value in numpy array, such that we could apply elementary operation to entire array instead of just a scalar value.\n  \n  * For variables and differentiation point, it will be input in Dual number instantiation as its variable value, and value as the point of differentiation.\n  User would also have to input the length of total variables and the position of current variable in dual class.\n\n  * The function is directly built upon operation on dual class initialized above.\n  \n  * In the futre, We will also plan to use the above cited parser package to parse the formula. \n  Then a formula data structure will then be created, encoding the user's input as an abstract syntax tree. In this way, we will implement the evaluation and differentiation.\n\n\n* **Implemented Classes**\n\n  * Forward mode (AutoDiff): This class implements differention and calculate derivatives through forward mode.\n\n  * Reverse mode (TBC*): This class will implement chain rule to calculate derivatives through reverse mode.\n\n  * Elementary function: This class will overwrite and redefine elementary functions, making them applicable on Dual object.\n \n  * `Dual`: dual number class. This class will take in any real number variable and construct and return it as a dual number,\n  all the subsequent operations in AutoDiff will be done on Dual Number class\n  The class also contains operations (addition, m) between dual numbers, and real numbers.\n \n* **Method and Attributes of the Classes**\n\n*Forward mode:*\n\n```python\ndef __init__(self, f, var):\n     self.f = f\n     self.var = var\n     \ndef get_value(self):\n    \"\"\" Returns the value of f\n        \n        Parameters\n        ----------\n        self: Forward object\n        \n        Returns\n        ------- \n        calculate the value of f on var through forward mode on specific value\n        \n        Examples\n        -------- \n        >>> fwd.get_value()\n    \"\"\"\n    return self.diff\n     \ndef get_der(self, *args):\n        \"\"\" Returns the derivative value of f\n        \n        Parameters\n        ----------\n        self: Forward object\n        **kwargs: x, y etc. Dual Number\n\n        Returns\n        ------- \n        calculate the derivative of f on var through forward mode on all variables\n        calculate the derivative of f on var through forward mode on specific variables\n        \n        Examples\n        -------- \n        >>> fwd.get_der()\n        >>> fwd.get_der(x1)\n        \"\"\"\n        return result\n\ndef get_jacobian(self, **kwargs):\n    # **kwargs: var = 'x','y' etc.\n    #  calculate the derivative of f on var through forward mode with jacobian\n    return self.diff\n     \ndef get_expression(self, **kwargs):\n    # **kwargs: var = 'x','y' etc.\n    # return the list of derivative expression of the parsed formula.\n    return self.express\n```\n\n   *Reverse mode: (A future implementation)*\n    \n    \n```python\ndef __init__(self, f, var):\n    self.f = f\n    self.var = var\n     \ndef get_value(self, **kwargs):\n   # **kwargs: var = 'all','x','y' etc.\n   # calculate the derivative of f on var through reverse mode to specific value\n    return self.f.val\n\ndef get_jacobian(self, **kwargs):\n   # **kwargs: var = 'all','x','y' etc.\n   # calculate the derivative of f on var through reverse mode with jacobian\n    return self.f.der\n     \ndef get_jacobian(self, **kwargs):\n   # **kwargs: var = 'all','x','y' etc.\n   # calculate the derivative of f on var through reverse mode with jacobian\n    return self.diff\n     \ndef get_expression(self, **kwargs):\n   # **kwargs: var = 'all','x','y' etc.\n   # return the list of derivative expression of the parsed formula.\n    return self.express\n```\n\n* **Dual Class** :\n  \n  The class instance itself has two main attributes: the value and the evaluated derivatives with respect to each input.\n  And within the class we redefine some of the elementary functions and basic algebraic operations, in order to calculate both evaluation values and derivation.\n  \n  1. Attributes\n\n  self.val: The evaluation values of the functions or the initialized values for the variable(dual object)\n  self.der: The derivatives of the functions or the initialized derivative of the variable. When there are multiple variables to be input in a function. \n \n```python\n\ndef __init__(self, real_number):\n    self.val = real_number\n    self.der = 1\n```\n\n\n  * **Elementary Function** :\n  \n  For the elementary function, we write our own method of computing the value so that these function can be applied on the Dual number, as well as on the real number. \n For example, in our daily usage, sine funtion on a real number `x` can be calculated via `NumPy` (np.sin(x)), but here when we calculate sine value for a Dual object, \n we cleverly store the value (same as we got from np.sin(x)) and the derivative part. \n\n We have implemented the following elementary functions and we provide a demo function for reference.\n```python\n#the function we have implemented so far\n\nexp() #extend the exponential function to Dual number\nlog() #extend the logrithmatic function with base e to Dual number\nsqrt() #extend the square root function with base e to Dual number\nsin() #extend the sine function with base e to Dual number\ncos() #extend the cosine function with base e to Dual number\ntan() #extend the tangent function with base e to Dual number\narcsin() #extend the inverse sine function with base e to Dual number\narccos() #extend the inverse cosine function with base e to Dual number\narctan() #extend the inverse tangent function with base e to Dual number\n\n\n ##demo function\ndef sin(dual):\n    \"\"\"Calculate the sine of the input\n        Keyword arguments:\n        dual -- a dual number or a real number\n        Return:\n        the sine value\n    \"\"\"\n    if isinstance(dual, Dual):\n        der = np.cos(dual.val)*dual.der\n        val = np.sin(dual.val)\n        return Dual(val,der)\n    else:\n        return np.sin(dual)\n             \n```\nIf we call the above function, it will give the following output. \n```python\n#...import necessary dependencies\n>>> x = Dual(np.pi, 1)\n>>> z = sin(x)\n>>> print(z)\nDual(value=1.2246467991473532e-16, derivative=-1.0)\n\n```\nNotice z is a Dual object. This function also applies to real number:\n```python\n#...import necessary dependencies\n>>> x_real = np.pi\n>>> z_real = sin(x_real)\n>>> print(z_real)\n1.2246467991473532e-16\n\n```\n\nIn the future, we may consider extending our elementary function libraries, including the hypobolic sine and cosine, as well as functions like csc and cot, log with base 2 and 10, if needed.\n\n* **External Dependencies**\n\nWe have the following external libraries/Modules to include:\n\n`NumPy`: This provides an API for a large collection of high-level mathematical operations. In addition, it provides support for array operations.\n\n`Math`: This provides access to some mathematical functions also.\n\n`parser`: (This is a future implementation)we will use standard library `parser` and extend it to parse the function when user enter as string, in the interface we will have built.\n\n`pytest`: This is the way we perform testing on our codes.\n\nAlso, we include Travis CI and CodeCov to make sure that the validility of building and the code. \n  \n* **Future implementation**\n\nPlease refer to section 6. Future Feature.\n\n\n","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00008-53e7b8b4-fd5e-4dd7-9f64-e92aed82cfc9"}},{"cell_type":"markdown","source":"## 6. Future Features\n\n* **Implement User Interface with elegant input**\n\n  Now that our package requires the user to initialize the variables using Dual class with specified location and length of the input variables. \n  And then user could use these Dual objects to create the target functions. However, there are mainly two future improvements that can be implemented to make the package more friendly to users.\n\n  1. With user entering the function expression, our package will automatically parse the function break it down into elementary functions and store them into tree structure.\n\n  When users want to repeatively use the functions that require our package to calculate the deriavtives, now the users have to redefine the funtions repeatively.\n  Once we could parse the function expressions and use tree structure to store the operations and input variables at each step, we can free users from initializing functions and variables repeatively.\n\n  2. With user directly entering the input variables for the target functions, our package will automatically initialize the Dual objects that will be used in the target functions.\n  \n  When users initialize the variables, they should first think about how many variables will be used in the target functions. But sometimes users may want to use the variables later in different functions.\n  Therefore, in the future we will use list to store the values that the user is intended to use in the function instead of the initialized variables. Our package will automatically initialize the variables for the user\n  with these values.\n\n* **Jacobian of multiple functions and multiple variables**\n\n  Now our package could deal with single function with multiple variables. But in the future, we will implement the case when the use will use multiple functions with multiple variables.\n  In this way, we will allow the value and derivatives to be array and combine the derivatives of different functions and variables together.\n\n*  **Reverse Mode of Auto Differentiation class**\n\n  Now our package could calculate deriavtives through forward mode of Auto Differentiation. However, in many tasks in machine learning, it is important to implement reverse mode to customize gradient descent in these problems.\n  To create class of reverse mode, we will modify the dual class into cantaining the input of each new-generated dual objects through operation. In this way, we can create a linked graph of this objects as nodes and then we can \n  sort them in topological order to get the reverse path. Then we can calculate the derivatives of the previous traces/objects of the current object/trace to gain the derivative of current object.\n\n*  **Expression and Visualization**\n\n  If time allows, we also plan to actualize expression and symbolic representation of differentiation. This would requires parsing of input function, \n  and store them in a tree (or other neccessary data structure), and recombine symbolic representation together after finishing differnetiation.\n  It could requires higher complexity.\n  Besides, if possible, we would also plan to visualize our computational graph in python via visualization package, e.g. d3. \n\n\n\n\n\n## 7. Reference\n\n[[1]](https://www.jmlr.org/papers/volume18/17-468/17-468.pdf): Baydin, Atilim Gunes; Pearlmutter, Barak; Radul, Alexey Andreyevich; Siskind, Jeffrey (2018). \"Automatic differentiation in machine learning: a survey\". Journal of Machine Learning Research. 18: 1–43.\n\n[[2]](https://fac.ksu.edu.sa/sites/default/files/numerical_analysis_9th.pdf):Rirchard L. Burden and J. Douglas Faires. Numerical Analysis. Brooks/Cole, 2001.\n\n[[3]](https://www.springer.com/gp/book/9783540654667):Johannes Grabmeier and Erich Kaltofen. Computer Algebra Handbook: Foundations, Applications, Systems. Springer, 2003\n\n[[4]](https://www.jstor.org/stable/24103956): Arun Verma. An introduction to automatic differentiation. Current Science, 78(7):804–7,\n2000.\n\n[[5]](https://www.worldcat.org/oclc/31441929):  Spivak, Michael. (1994). *Calculus* (3rd ed.). Houston, Tex.: Publish or Perish. p. 359.\n\n\n## 8. Feedback\n\n### 8.1 Milestone1\n\n* Your document looks professional!Your introduction and background are great. And your following demo codes are neat and clear. \n\n  Thank you!\n \n\n* It's nice to include the explanations of reverse mode if you want to implement it as an additional feature. \n\n  We re-organized our background part into the elementary function, the chain rule, the forward mode, the backward mode, and the dual number class. The forward mode section contains explanations and illustration of trace table and graph,\n the backward mode also contains explanation, and graphical illustrations of operation. The dual number class is a new feature, we included because we think this is a bettter and efficient way to \n deal with elementary functions. We also included chain rule explanation as before.\n \n\n* Implementation: it would be better if you could elaborate on how to deal with elementary functions, e.g. by giving some demos.\n\n  We add an example code of sin function to illustrate how we are dealing with elementary functions, notice that in the newest version we relate this to the dual number class.","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00010-0b1c50f6-57dd-4f7f-9517-3593b699adcc"}},{"cell_type":"markdown","source":"","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00011-6d1b84a4-3c68-42ee-8309-516a085dbe17"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"078a9702-74f1-43cd-b3c6-5dd3fa0ea855","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}}}